{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03_text_distance_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JhonFiUNFV/python_prep/blob/master/03_text_distance_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdUFcDsdzRyw"
      },
      "source": [
        "# Clonamos el repositorio para obtener los dataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHReFf3_y9ms",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "6b2f123d-3a40-4d7a-e901-7d3b0a9c50b0"
      },
      "source": [
        "!git clone https://github.com/joanby/tensorflow.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'tensorflow'...\n",
            "remote: Enumerating objects: 51, done.\u001b[K\n",
            "remote: Counting objects: 100% (51/51), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 60311 (delta 32), reused 37 (delta 23), pack-reused 60260\u001b[K\n",
            "Receiving objects: 100% (60311/60311), 442.46 MiB | 14.79 MiB/s, done.\n",
            "Resolving deltas: 100% (82/82), done.\n",
            "Checking out files: 100% (60225/60225), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNKZXgtKzU2x"
      },
      "source": [
        "# Damos acceso a nuestro Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gu7KWnzzUQ0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gUxIkHWzfHV"
      },
      "source": [
        "# Test it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIQt3jBMzYRE"
      },
      "source": [
        "!ls '/content/drive/My Drive' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHsK36uN0XB-"
      },
      "source": [
        "# Google colab tools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTzwfUPWzrm4"
      },
      "source": [
        "from google.colab import files # Para manejar los archivos y, por ejemplo, exportar a su navegador\n",
        "import glob # Para manejar los archivos y, por ejemplo, exportar a su navegador\n",
        "from google.colab import drive # Montar tu Google drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQQ8nLiMY6wM"
      },
      "source": [
        "##Especificando la versión de TensorFlow\n",
        "\n",
        "Ejecutando \"importar tensorflow\" importará la versión por defecto (actualmente 2.x). Puedes usar la 1.x ejecutando una celda con la \"versión mágica de tensorflow\" **antes de ejecutar \"importar tensorflow\".\n",
        "\n",
        "### Si no funciona hacer el pip install\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j---G3ZY6wN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f363a778-c70c-4292-b3c6-5024ef8c2657"
      },
      "source": [
        "#!pip install tensorflow==1.14\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-OIfuWLujbt"
      },
      "source": [
        "# Importar Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPSus73fumtP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2091392c-b46b-4e22-86d7-9a58d3b5b444"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQheSGsEBdD3"
      },
      "source": [
        "session = tf.Session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzlBylUEmQJ0"
      },
      "source": [
        "# Distancia de Levenshtein"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDX1L5E56ssX"
      },
      "source": [
        "$x,y\\in S$ donde $S$ es el conjunto de Strings, entonces $d(x,y)$ se define como el número de operaciones (ediciones) para convertir la palabra $x$ en la palabra $y$, donde las ediciones posibles de la palabra son:\n",
        "- insertar un nuevo caracter\n",
        "- eliminar un caracter de la palabra\n",
        "- sustituir un caracter por otro"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpjDgYSa5-j8"
      },
      "source": [
        "hypothesis = list('casa')\n",
        "truth = list('calle')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ41NQPv6AGg"
      },
      "source": [
        "h1 = tf.SparseTensor([[0,0,0], [0,0,1], [0,0,2], [0,0,3]],\n",
        "                    hypothesis, [1,1,1])\n",
        "t1 = tf.SparseTensor([[0,0,0], [0,0,1], [0,0,2], [0,0,3], [0,0,4]],\n",
        "                    truth, [1,1,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4hGsOTe6Bjk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c0626a5-64ba-4e9e-eda8-c249d182c2df"
      },
      "source": [
        "print(session.run(tf.edit_distance(h1, t1, normalize=False)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87y7oBlz6DAD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46ad3624-878b-490b-d10f-708ea5c63fef"
      },
      "source": [
        "print(session.run(tf.edit_distance(h1, t1, normalize=True)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgblvoIy6EOL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "4f873996-5e98-4f74-e611-274b9da02826"
      },
      "source": [
        "session.run(h1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SparseTensorValue(indices=array([[0, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       [0, 0, 2],\n",
              "       [0, 0, 3]]), values=array([b'c', b'a', b's', b'a'], dtype=object), dense_shape=array([1, 1, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwjVIkin6Ft8"
      },
      "source": [
        "hypothesis2 = list('casacalle')\n",
        "truth2 = list('callescalles')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_7KuJlb6HqW"
      },
      "source": [
        "h2 = tf.SparseTensor([[0,0,0], [0,0,1], [0,0,2], [0,0,3], [0,1,0], [0,1,1], [0,1,2],[0,1,3],[0,1,4]],\n",
        "                    hypothesis2, [1,2,4])\n",
        "t2 = tf.SparseTensor([[0,0,0], [0,0,1],[0,0,2],[0,0,3],[0,0,4], [0,0,5], \n",
        "                      [0,1,0],[0,1,1],[0,1,2],[0,1,3],[0,1,4],[0,1,5]],\n",
        "                    truth2, [1,2,6])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFGZV9QN6IlO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7b0c1504-77d1-4935-887e-beaf97c07236"
      },
      "source": [
        "print(session.run(tf.edit_distance(h2,t2,normalize=False)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrPfMbxV6Jpg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "985e63f0-e738-475b-bb90-c540af518def"
      },
      "source": [
        "print(session.run(tf.edit_distance(h2,t2,normalize=True)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.6666667  0.16666667]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKs26anM6Kn9"
      },
      "source": [
        "hypothesis_words = [\"casa\", \"casita\", \"caseron\", \"tensor\", \"python\"]\n",
        "truth_word = \"algoritmo\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0ATroHI6Lml",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "3ba52cec-f913-4ea0-eecb-6595f7a2a7ba"
      },
      "source": [
        "num_h_words = len(hypothesis_words)\n",
        "h_idx = [[xi,0,yi] for xi,x in enumerate(hypothesis_words) for yi,y in enumerate(x)]\n",
        "h_idx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0, 0],\n",
              " [0, 0, 1],\n",
              " [0, 0, 2],\n",
              " [0, 0, 3],\n",
              " [1, 0, 0],\n",
              " [1, 0, 1],\n",
              " [1, 0, 2],\n",
              " [1, 0, 3],\n",
              " [1, 0, 4],\n",
              " [1, 0, 5],\n",
              " [2, 0, 0],\n",
              " [2, 0, 1],\n",
              " [2, 0, 2],\n",
              " [2, 0, 3],\n",
              " [2, 0, 4],\n",
              " [2, 0, 5],\n",
              " [2, 0, 6],\n",
              " [3, 0, 0],\n",
              " [3, 0, 1],\n",
              " [3, 0, 2],\n",
              " [3, 0, 3],\n",
              " [3, 0, 4],\n",
              " [3, 0, 5],\n",
              " [4, 0, 0],\n",
              " [4, 0, 1],\n",
              " [4, 0, 2],\n",
              " [4, 0, 3],\n",
              " [4, 0, 4],\n",
              " [4, 0, 5]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-AVeGa_6Mz8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "41b5daba-91d4-46e1-fd56-d964712f8987"
      },
      "source": [
        "h_chars = list(''.join(hypothesis_words))\n",
        "h_chars"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['c',\n",
              " 'a',\n",
              " 's',\n",
              " 'a',\n",
              " 'c',\n",
              " 'a',\n",
              " 's',\n",
              " 'i',\n",
              " 't',\n",
              " 'a',\n",
              " 'c',\n",
              " 'a',\n",
              " 's',\n",
              " 'e',\n",
              " 'r',\n",
              " 'o',\n",
              " 'n',\n",
              " 't',\n",
              " 'e',\n",
              " 'n',\n",
              " 's',\n",
              " 'o',\n",
              " 'r',\n",
              " 'p',\n",
              " 'y',\n",
              " 't',\n",
              " 'h',\n",
              " 'o',\n",
              " 'n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Naxvs66g6NxA"
      },
      "source": [
        "h3 = tf.SparseTensor(h_idx, h_chars, [num_h_words, 1, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSTj3uxd6O4p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d2deb717-109b-4e1b-9b18-29cf9013b9b6"
      },
      "source": [
        "truth_word_vect = [truth_word]*num_h_words\n",
        "truth_word_vect"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['algoritmo', 'algoritmo', 'algoritmo', 'algoritmo', 'algoritmo']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVWvmwXG6QC9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "outputId": "0ef3d269-36f6-4d17-c49d-72b516cf2730"
      },
      "source": [
        "t_idx = [[xi,0,yi] for xi,x in enumerate(truth_word_vect) for yi, y in enumerate(x)]\n",
        "t_idx"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 0, 0],\n",
              " [0, 0, 1],\n",
              " [0, 0, 2],\n",
              " [0, 0, 3],\n",
              " [0, 0, 4],\n",
              " [0, 0, 5],\n",
              " [0, 0, 6],\n",
              " [0, 0, 7],\n",
              " [0, 0, 8],\n",
              " [1, 0, 0],\n",
              " [1, 0, 1],\n",
              " [1, 0, 2],\n",
              " [1, 0, 3],\n",
              " [1, 0, 4],\n",
              " [1, 0, 5],\n",
              " [1, 0, 6],\n",
              " [1, 0, 7],\n",
              " [1, 0, 8],\n",
              " [2, 0, 0],\n",
              " [2, 0, 1],\n",
              " [2, 0, 2],\n",
              " [2, 0, 3],\n",
              " [2, 0, 4],\n",
              " [2, 0, 5],\n",
              " [2, 0, 6],\n",
              " [2, 0, 7],\n",
              " [2, 0, 8],\n",
              " [3, 0, 0],\n",
              " [3, 0, 1],\n",
              " [3, 0, 2],\n",
              " [3, 0, 3],\n",
              " [3, 0, 4],\n",
              " [3, 0, 5],\n",
              " [3, 0, 6],\n",
              " [3, 0, 7],\n",
              " [3, 0, 8],\n",
              " [4, 0, 0],\n",
              " [4, 0, 1],\n",
              " [4, 0, 2],\n",
              " [4, 0, 3],\n",
              " [4, 0, 4],\n",
              " [4, 0, 5],\n",
              " [4, 0, 6],\n",
              " [4, 0, 7],\n",
              " [4, 0, 8]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LewpBJLZ6RiZ"
      },
      "source": [
        "t_chars = list(''.join(truth_word_vect))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QGTy2Vw6Se5"
      },
      "source": [
        "t3 = tf.SparseTensor(t_idx, t_chars, [num_h_words,1,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCqZsf506TZU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ccd26b45-6137-4f7d-f939-541cf3883005"
      },
      "source": [
        "print(session.run(tf.edit_distance(h3, t3, normalize=False)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9.]\n",
            " [7.]\n",
            " [8.]\n",
            " [8.]\n",
            " [8.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjBGXk9h6U1j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "34233f64-0cbc-4ec5-974b-bccc8cb14f0d"
      },
      "source": [
        "print(session.run(tf.edit_distance(h3, t3, normalize=True)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.       ]\n",
            " [0.7777778]\n",
            " [0.8888889]\n",
            " [0.8888889]\n",
            " [0.8888889]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njjbGXXA6Z31"
      },
      "source": [
        "def create_sparse_words_vect(word_list):\n",
        "    num_words = len(word_list)\n",
        "    idx = [[xi,0,yi] for xi,x in enumerate(word_list) for yi, y in enumerate(x)]\n",
        "    chars = list(''.join(word_list))\n",
        "    return tf.SparseTensorValue(idx, chars, [num_words, 1, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aCz3HtH6a4h"
      },
      "source": [
        "hyp_string_sp = create_sparse_words_vect(hypothesis_words)\n",
        "tr_string_sp = create_sparse_words_vect([truth_word]*len(hypothesis_words))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xexU-plW6cBh"
      },
      "source": [
        "h_input = tf.sparse_placeholder(dtype=tf.string)\n",
        "t_input = tf.sparse_placeholder(dtype=tf.string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Kcup-J36dEW"
      },
      "source": [
        "edit_distance = tf.edit_distance(h_input, t_input, normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfwSj9vF6eJx"
      },
      "source": [
        "feed_dict = {h_input:hyp_string_sp, t_input:tr_string_sp}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaqlQhUs6fQA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "fd1d0ad0-1f11-40c8-e5df-0c977918c3c6"
      },
      "source": [
        "print(session.run(edit_distance, feed_dict=feed_dict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.       ]\n",
            " [0.7777778]\n",
            " [0.8888889]\n",
            " [0.8888889]\n",
            " [0.8888889]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XypI9bBH7Tby"
      },
      "source": [
        "# Otras distancias para comparar palabras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwzkCefe7VOB"
      },
      "source": [
        "### Distancia de Hamming\n",
        "- Número de caracteres iguales en la misma posición. \n",
        "- Las dos palabras deben ser de la misma longitud\n",
        "$$D(s_1,s_2) = \\sum_{i=1}^n I_i$$\n",
        "donde $I_i=1$ si las dos palabras tienen el mismo caracter en la posición i-ésima  y 0 en otro caso"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OEkJlLE7WmT"
      },
      "source": [
        "### Distancia del Coseno\n",
        "- Obtenemos el producto escalar del vector de k-gramas de cada palabra dividida por la norma dos de los mismos\n",
        "$$D(s_1,s_2) = 1 - \\frac{k(s_1)\\cdot k(s_2)}{||k(s_1)||||k(s_2)||}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZa-GACK7Wim"
      },
      "source": [
        "### Distancia de Jaccard\n",
        "- Numero de caracteres en común entre las dos palabras dividido por la unión total de caracteres de ambas palabras\n",
        "$$D(s_1,s_2) = \\frac{|s_1\\cap s_2|}{|s_1\\cup s_2|}$$"
      ]
    }
  ]
}